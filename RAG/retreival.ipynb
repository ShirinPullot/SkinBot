{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import psycopg2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pgvector.psycopg2 import register_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('/Users/shirinwadood/Desktop/projects/SkinBot/RAG/preprocessing_data/preproc_articles.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chunk the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_document(df, max_tokens, token_overlap):\n",
    "    \"\"\"\n",
    "    Splits a document into chunks each containing at most max_tokens tokens.\n",
    "    \"\"\"\n",
    "    chunk_list = []\n",
    "\n",
    "    for i in range(len(df.index)):\n",
    "        text = df['articles'][i]\n",
    "        tokens = word_tokenize(text)\n",
    "        num_tokens = len(tokens)\n",
    "        start = 0\n",
    "        while start < num_tokens: \n",
    "            end = min(start + max_tokens, num_tokens)\n",
    "            current_chunk = tokens[start:end]\n",
    "            chunk_list.append((' '.join(current_chunk)))  # Store document index along with the chunk\n",
    "            start += max_tokens - token_overlap # Increment start by at least max_tokens - token_overlap\n",
    "\n",
    "    return chunk_list\n",
    "\n",
    "chunks_list = chunk_document(df, max_tokens=300, token_overlap=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the embeddings of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-small\")\n",
    "model = AutoModel.from_pretrained(\"thenlper/gte-small\")\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "def get_embeddings(input_texts: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of input texts.\n",
    "\n",
    "    Args:\n",
    "        input_texts (List[str]): List of input texts.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string representing the embeddings.\n",
    "    \"\"\"\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(input_texts, max_length=120, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    embeddings_list = embeddings.numpy().tolist()\n",
    "\n",
    "    return embeddings_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Chunk  \\\n",
      "0  can i keep my skin looking young and healthy w...   \n",
      "1  them . outcome are often based on a subjective...   \n",
      "2  ’ re pregnant or breastfeeding.check the produ...   \n",
      "3  forget to apply sunscreen to your chest and ha...   \n",
      "4  not healing well . if you notice any change , ...   \n",
      "\n",
      "                                           Embedding  \n",
      "0  [-0.03198978677392006, 0.007969328202307224, 0...  \n",
      "1  [-0.05294744297862053, 0.011631992645561695, 0...  \n",
      "2  [-0.03757018595933914, -0.028628941625356674, ...  \n",
      "3  [-0.029223192483186722, -0.008009245619177818,...  \n",
      "4  [-0.04224391281604767, -0.030831916257739067, ...  \n"
     ]
    }
   ],
   "source": [
    "embedded_df = pd.DataFrame(columns=['Chunk', 'Embedding'])\n",
    "\n",
    "# Iterate through the chunked articles and get their embeddings\n",
    "for chunk in chunks_list:\n",
    "    embeddings = get_embeddings([chunk])\n",
    "    embedded_df.loc[len(embedded_df)] = {'Chunk': chunk, 'Embedding': embeddings[0]}\n",
    "\n",
    "\n",
    "print(embedded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i keep my skin looking young and healthy w...</td>\n",
       "      <td>[-0.03198978677392006, 0.007969328202307224, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>them . outcome are often based on a subjective...</td>\n",
       "      <td>[-0.05294744297862053, 0.011631992645561695, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’ re pregnant or breastfeeding.check the produ...</td>\n",
       "      <td>[-0.03757018595933914, -0.028628941625356674, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forget to apply sunscreen to your chest and ha...</td>\n",
       "      <td>[-0.029223192483186722, -0.008009245619177818,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not healing well . if you notice any change , ...</td>\n",
       "      <td>[-0.04224391281604767, -0.030831916257739067, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Chunk  \\\n",
       "0  can i keep my skin looking young and healthy w...   \n",
       "1  them . outcome are often based on a subjective...   \n",
       "2  ’ re pregnant or breastfeeding.check the produ...   \n",
       "3  forget to apply sunscreen to your chest and ha...   \n",
       "4  not healing well . if you notice any change , ...   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [-0.03198978677392006, 0.007969328202307224, 0...  \n",
       "1  [-0.05294744297862053, 0.011631992645561695, 0...  \n",
       "2  [-0.03757018595933914, -0.028628941625356674, ...  \n",
       "3  [-0.029223192483186722, -0.008009245619177818,...  \n",
       "4  [-0.04224391281604767, -0.030831916257739067, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedded_df.to_csv('embedded_articles.csv', index=False)\n",
    "\n",
    "embedded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Successfully connected to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost dbname=ragdb user=myusername password=mypassword\")\n",
    "    \n",
    "cur = conn.cursor()\n",
    "\n",
    "print('Successfully connected to PostgreSQL.')\n",
    "\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup the Database to save the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_vector(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ragdb (\n",
    "    id bigserial primary key, \n",
    "    Chunk text,\n",
    "    Embedding vector(384)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Open a cursor\n",
    "with conn.cursor() as cur:\n",
    "    # Execute the table creation command\n",
    "    cur.execute(table_create_command)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "data_list = [(row['Chunk'], np.array(row['Embedding'])) for index, row in embedded_df.iterrows()]\n",
    "sql_query = 'INSERT INTO ragdb (Chunk, Embedding) VALUES (%s, %s)'\n",
    "\n",
    "\n",
    "# Open a cursor again\n",
    "with conn.cursor() as cur:\n",
    "    try:\n",
    "        # Executing the SQL query with the data\n",
    "        cur.executemany(sql_query, data_list)\n",
    "        \n",
    "        # Committing the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions (print, log, etc.)\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vector records in table:  17 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    cur.execute(\"SELECT COUNT(*) as cnt FROM ragdb;\")\n",
    "    num_records = cur.fetchone()[0]\n",
    "    print(\"Number of vector records in table: \", num_records,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First record in table:  [(204, 'can i keep my skin looking young and healthy without paying for expensive procedure ? a : after doing a deep dive of the medical literature , my advice is to follow a simple routine : live well every day with tip and guidance on food , fitness and mental health , delivered to your inbox every thursday.arrowrightin the morning : use a face cleanser , then apply a moisturizer and a broad-spectrum sunscreen.at night : cleanse your face again , then apply a retinoid and your moisturizer.the brand doesn ’ t necessarily matter . chose what work for your budget and skin type — such a sensitive , dry or oily.skip to end of carouselstart the year freshkatty huertas/the poststart with practical tip and smart solution for your health , technology , travel , food , money , home and more . easy win , good habit , better living . elevate your daily life with expertise from the washington post.find it all here.end of carouselbe skeptical of social medium and adslook , i ’ m not immune to the bait of fancy lotion extolled by people with absurdly dewy skin on tiktok . but i also don ’ t want to waste my time and money.ads for anti-aging product often tout a clinical study backing them , which might make you think they ’ re worth your money . but there are few strong placebo-controlled , blinded randomized trial in human for over-the-counter product — much le one that weren ’ t sponsored by the brand profiting from them . outcome are often based on a subjective appearance of improvement , not on something measured microscopically . personally , i ’ d like to see both.advertisementfor example , product like alpha hydroxy acid and antioxidant like vitamin c', array([-3.19897868e-02,  7.96932820e-03,  4.64758687e-02,  3.01320814e-02,\n",
      "        1.17819319e-02,  9.03075747e-03,  4.97183539e-02,  2.01667789e-02,\n",
      "       -6.17691986e-02, -2.97576608e-03,  9.88343731e-03, -6.49698824e-02,\n",
      "        3.44051309e-02,  5.13664261e-02,  2.35802997e-02,  4.20562830e-03,\n",
      "        5.61014414e-02,  2.69305259e-02, -5.75080179e-02,  5.51274940e-02,\n",
      "        1.04117878e-02, -1.60941854e-02, -5.04511781e-02, -4.86957356e-02,\n",
      "        6.01638556e-02, -1.89598538e-02,  5.23591414e-04, -2.31725238e-02,\n",
      "       -2.82624401e-02, -1.98321611e-01,  1.91724207e-02, -6.38389215e-02,\n",
      "        7.12790480e-03, -3.61548886e-02, -6.83829468e-03, -3.56834307e-02,\n",
      "       -2.35376898e-02,  6.11611269e-02,  6.26265130e-04,  4.97821122e-02,\n",
      "       -4.69601742e-04, -1.68174529e-03, -7.06303045e-02, -2.61424854e-02,\n",
      "       -1.70458611e-02, -1.15710646e-02, -1.87849291e-02,  1.05549488e-02,\n",
      "        9.29520503e-02, -6.79060724e-03,  3.96485291e-02, -1.67160295e-02,\n",
      "        9.84622445e-03,  4.27104048e-02,  9.78924334e-03,  3.32535841e-02,\n",
      "        6.00964502e-02,  1.44278770e-02,  2.46553123e-02,  7.93153197e-02,\n",
      "       -6.85909716e-03,  3.31673399e-02, -1.66967571e-01,  1.45089939e-01,\n",
      "        1.87003855e-02,  4.04461436e-02,  1.19181639e-02, -1.52573595e-02,\n",
      "        1.68021433e-02,  4.33769934e-02, -4.84983772e-02,  1.20019270e-02,\n",
      "        3.63210663e-02,  4.40737382e-02,  1.12505155e-02, -3.45920026e-02,\n",
      "        1.36356726e-02, -2.91806292e-02,  2.79028015e-03,  1.07647171e-02,\n",
      "       -1.04888417e-02,  1.46377319e-02, -1.47099383e-02,  7.17333704e-03,\n",
      "       -2.00099070e-02, -3.65007818e-02, -2.60871346e-03, -5.63212484e-02,\n",
      "        3.96532975e-02,  2.32158005e-02, -2.14752331e-02, -3.14586833e-02,\n",
      "       -4.35614102e-02, -2.86520571e-02, -4.71349247e-02, -2.69349925e-02,\n",
      "        3.39033790e-02,  3.26775946e-02, -8.74089748e-02,  2.29263142e-01,\n",
      "       -7.16266185e-02, -1.30374441e-02,  1.97889693e-02, -1.98459756e-02,\n",
      "       -5.77137200e-03, -6.77067712e-02, -3.05332132e-02, -7.82033056e-03,\n",
      "       -3.39896381e-02,  2.67538894e-02,  2.76405159e-02, -9.41192172e-03,\n",
      "        1.92339830e-02, -5.59506379e-02,  3.76176760e-02,  4.14882600e-02,\n",
      "        6.52268231e-02,  3.19890417e-02, -3.22709829e-02, -4.47088405e-02,\n",
      "       -6.34790026e-03, -1.28720496e-02,  3.70481387e-02, -5.76835359e-03,\n",
      "       -2.06930493e-03, -5.88970222e-02,  7.35921711e-02,  8.36031437e-02,\n",
      "        1.28218625e-02,  5.43235913e-02,  3.26739214e-02, -5.92526756e-02,\n",
      "       -3.22300047e-02, -4.19247476e-03, -7.23906979e-03, -6.84698718e-03,\n",
      "       -1.97746642e-02, -1.49476118e-02,  4.38278951e-02, -3.99142131e-02,\n",
      "       -3.94623578e-02, -6.93451464e-02,  2.10505072e-02, -1.06001012e-01,\n",
      "        6.01612777e-02,  1.02645047e-01,  2.97694858e-02,  7.33562186e-02,\n",
      "       -3.94252725e-02, -1.37469983e-02, -1.26118157e-02,  4.16075736e-02,\n",
      "        4.94945236e-03,  9.96923354e-03,  3.30059268e-02,  1.45533110e-03,\n",
      "        6.58714473e-02, -1.01544280e-02, -2.98900064e-02, -1.16866725e-02,\n",
      "       -9.43072513e-03, -7.73238949e-03, -2.93827076e-02,  5.79358824e-02,\n",
      "        3.97748593e-03, -7.73036405e-02, -5.15011838e-03, -2.37341542e-02,\n",
      "       -1.95377134e-03,  1.85659656e-03,  4.86645140e-02,  7.11318804e-03,\n",
      "       -1.87799279e-02,  6.15417510e-02,  9.80928540e-02, -1.01468386e-02,\n",
      "       -2.55355779e-02,  1.37878051e-02,  8.58972315e-03,  3.07405684e-02,\n",
      "        5.71122505e-02, -2.28081793e-02, -2.73160636e-02,  3.68661783e-03,\n",
      "        2.01297719e-02, -7.95044228e-02,  9.14131291e-03, -1.61222275e-02,\n",
      "        2.78461073e-02, -9.47115198e-03, -4.52667214e-02, -3.13655776e-03,\n",
      "       -7.07902461e-02, -3.48627451e-03, -5.26173897e-02, -2.10893657e-02,\n",
      "       -7.09482506e-02, -5.22816405e-02, -6.50350936e-03, -2.57445015e-02,\n",
      "        2.39584632e-02, -1.62855480e-02,  5.79208834e-03,  7.67199025e-02,\n",
      "        1.18960384e-02,  5.51662259e-02, -1.63627658e-02, -2.63153650e-02,\n",
      "        1.46775782e-01,  1.71827003e-02, -2.72209868e-02,  5.45184910e-02,\n",
      "        6.77463338e-02, -5.96561143e-03, -8.40899348e-02,  1.99275389e-02,\n",
      "        4.03781384e-02,  2.40845140e-02, -5.73172141e-03, -7.47326703e-04,\n",
      "        9.27490294e-02, -2.79468764e-02, -8.56425986e-02, -2.48182595e-01,\n",
      "        4.00728025e-02,  1.15170227e-02,  5.41522680e-03,  8.26291069e-02,\n",
      "       -5.08553758e-02,  3.89407435e-03, -3.81854884e-02,  6.37764856e-02,\n",
      "        7.12625012e-02,  8.41505826e-02, -5.32939583e-02, -1.52104991e-02,\n",
      "        2.70038359e-02, -4.50492240e-02,  5.92507571e-02,  5.99847622e-02,\n",
      "       -2.05513393e-03, -1.08343305e-03, -7.67840892e-02, -2.09976992e-04,\n",
      "       -4.55581583e-03,  2.76180822e-02, -6.52120039e-02,  1.05131634e-01,\n",
      "       -1.26262391e-02,  2.31069073e-01,  5.58129773e-02,  1.74355507e-02,\n",
      "       -3.27855088e-02,  6.15970865e-02, -1.12102379e-03, -1.12810628e-02,\n",
      "       -1.35515630e-01,  3.98995765e-02,  1.52073870e-03,  1.27480654e-02,\n",
      "       -2.05487814e-02, -7.41281211e-02, -3.53411138e-02,  2.18968373e-02,\n",
      "        9.25395265e-03, -3.08572948e-02, -4.38740477e-02, -7.04827905e-02,\n",
      "       -1.12439180e-02, -4.05018963e-02,  1.46887796e-02, -3.62744443e-02,\n",
      "       -3.04554738e-02,  3.16566229e-02, -5.25125023e-03,  4.07225033e-03,\n",
      "        8.68732110e-03,  1.56246070e-02, -7.97607154e-02, -1.14486217e-01,\n",
      "        4.78854543e-03, -3.71018201e-02,  2.57934798e-02, -2.77620126e-02,\n",
      "        1.32881841e-02,  1.39743406e-02, -3.99541371e-02,  7.38625675e-02,\n",
      "        9.41547472e-03,  4.89383265e-02, -7.28681162e-02,  5.55233993e-02,\n",
      "       -3.07347327e-02, -4.72337417e-02,  8.73338357e-02, -7.18809441e-02,\n",
      "       -2.74643321e-02,  2.59190798e-02,  2.70992592e-02,  3.79037000e-02,\n",
      "       -1.42793357e-02, -1.50817847e-02, -5.66421188e-02,  3.65864150e-02,\n",
      "       -7.09251910e-02,  2.45695915e-02,  5.83489202e-02,  3.20206098e-02,\n",
      "        2.12153373e-03,  3.28357555e-02, -4.26288284e-02,  1.80054866e-02,\n",
      "       -5.23516871e-02,  1.94906276e-02,  2.29670964e-02, -3.49259041e-02,\n",
      "       -3.72493565e-02,  2.18524691e-02, -1.91914793e-02, -2.33505294e-01,\n",
      "        1.61887072e-02, -3.37540358e-02,  5.05995601e-02, -2.30682176e-02,\n",
      "       -5.09468326e-03,  3.75441499e-02,  5.73197864e-02, -5.49643040e-02,\n",
      "        5.50027192e-03,  4.65860032e-02,  4.64130268e-02,  1.62041448e-02,\n",
      "       -2.08580717e-02,  5.14272181e-03, -3.50939035e-02,  4.94868532e-02,\n",
      "       -1.63958985e-02,  2.46648975e-02, -5.11205010e-02,  3.27043384e-02,\n",
      "       -2.64602397e-02,  1.74000025e-01, -4.28396426e-02,  4.63830978e-02,\n",
      "        5.74683547e-02, -1.80215985e-02,  1.84176024e-02,  4.38095815e-02,\n",
      "       -9.29320510e-03,  5.02442606e-02, -1.46774735e-04,  5.22074029e-02,\n",
      "       -1.84346326e-02,  4.06176969e-02,  1.62157305e-02, -5.82436882e-02,\n",
      "        2.42743995e-02,  1.31425457e-02, -6.56187255e-03, -8.54987651e-03,\n",
      "        2.47179018e-03, -1.47974240e-02,  1.89834777e-02,  1.13291942e-01,\n",
      "       -1.24999002e-01, -3.36415246e-02, -4.70370129e-02, -6.37486996e-03,\n",
      "       -1.94071736e-02, -5.05728535e-02, -2.30198056e-02,  3.99933457e-02,\n",
      "       -1.07768495e-02,  1.79206617e-02, -9.09261033e-03, -4.95085157e-02,\n",
      "       -1.23653393e-02, -2.43097786e-02,  1.49150100e-02, -1.18240539e-03,\n",
      "       -4.43550535e-02, -6.03135191e-02,  6.54990673e-02,  2.04351209e-02],\n",
      "      dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\n",
    "    # print the first record in the table, for sanity-checking\n",
    "    cur.execute(\"SELECT * FROM ragdb LIMIT 1;\")\n",
    "    records = cur.fetchall()\n",
    "    print(\"First record in table: \", records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create an index on the data for faster retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate the index parameters according to best practices\n",
    "num_lists = num_records / 1000\n",
    "if num_lists < 10:\n",
    "   num_lists = 10\n",
    "if num_records > 1000000:\n",
    "   num_lists = math.sqrt(num_records)\n",
    "with conn.cursor() as cur:\n",
    "   try:\n",
    "\n",
    "\n",
    "      #use the cosine distance measure, which is what we'll later use for querying\n",
    "      cur.execute(f'CREATE INDEX ON ragdb USING ivfflat (Embedding vector_cosine_ops) WITH (lists = {num_lists});')\n",
    "\n",
    "      conn.commit()\n",
    "   except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"An error occurred: {e}\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retreive the relevant context from PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3_similar_docs(query):\n",
    "    batch_dict = tokenizer(query, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "    # (Optionally) normalize embeddings\n",
    "    query_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    query_embeddings = embeddings.numpy().tolist()\n",
    "    query_embeddings = np.array(embeddings).flatten()\n",
    "\n",
    "    # Register pgvector extension\n",
    "    cur = conn.cursor()\n",
    "    # cur.execute(\"SELECT content FROM embeddings ORDER BY embedding <=> %s LIMIT 3\", (embeddings,))\n",
    "    cur.execute(\"SELECT Chunk, 1- (Embedding <=> %s) AS cosine_similarity FROM ragdb ORDER BY cosine_similarity DESC LIMIT 1\", (query_embeddings,))\n",
    "    top3_docs = cur.fetchall()\n",
    "    return top3_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('. by now , you should know the line well : apply sunscreen every day , even when it ’ s gray or cold , even when you ’ re covered up . when you are exposed , reapply every two hour . make sure your sunscreen protects against both uva and uvb ray . if skin cancer and sun damage aren ’ t enough to convince you , uv exposure is also thenumber onecause of wrinkle , uneven skin tone , loss of firmness and aging signs.exfoliationhere ’ s a product you might not need or want to apply every day . if you have dry skin , including winter-air-induced dry skin , you may exfoliate more than usual , but you should still keep it to once or twice a week – max . exfoliation can be used after cleanser but before moisturizer , a it help to remove flaky skin by increasing skin cell turnover . the benefit are real – removing dead skin and buildup for smoother skin and clearer pore – but most dermatologist will recommend chemical exfoliants over scrub to prevent damage to the protective barrier of your skin.serumanother optional addition to your skin care routine , serum contain ingredient like antioxidant or retinol that support skin health in a number of way , such a calming redness and improving texture and firmness.when you should use whatthe easiest way to remember when you should be doing what for your skin is to think of it like this : morning skin care should focus on prevention and protection for the day and your nighttime routine should focus on cleansing and repair.most people will only need to really wash their face once a day . in the morning , rinsing with warm water before applying moisturizer',\n",
       "  0.899026895150579)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_topic = get_top3_similar_docs('when should i use suncreen\"')\n",
    "related_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate the answer using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c47e5db6f44448285d5e425c2728fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765fce9a9566406a88d4fef51c21f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536046e8a5564b9997d89df1e22ca0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"llmware/bling-stable-lm-3b-4e1t-v0\", trust_remote_code = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Every day, even when it is cloudy or cold, even when you are covered up.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM  \n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the tokenizer and model\n",
    "llm_model = \"llmware/bling-stable-lm-3b-4e1t-v0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_model, torch_dtype=torch.bfloat16,trust_remote_code = True)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "entries = {}\n",
    "entries['context'] = related_topic[0][0]\n",
    "entries['query'] = \"when should i use suncreen\"\n",
    "\n",
    "# prepare prompt packaging used in fine-tuning process\n",
    "new_prompt = \"<human>: \" + entries[\"context\"] + \"\\n\" + entries[\"query\"] + \"\\n\" + \"<bot>:\"\n",
    "\n",
    "inputs = tokenizer(new_prompt, return_tensors=\"pt\")  \n",
    "start_of_output = len(inputs.input_ids[0])\n",
    "max_new_tokens = 100\n",
    "# config = transformers.GenerationConfig() \n",
    "# config.eos_token_id = tokenizer.eos_token_id\n",
    "outputs = model.generate(\n",
    "        inputs.input_ids.to(device),\n",
    "        attention_mask=inputs.attention_mask.to(device),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "\n",
    "output_only = tokenizer.decode(outputs[0][start_of_output:],skip_special_tokens=True)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "output_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns=['Model', 'Output', 'Max_Tokens', 'time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_df.loc[len(output_df)] = {'Model': llm_model, 'Output': output_only, 'Max_Tokens': max_new_tokens,'time': elapsed_time }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Output</th>\n",
       "      <th>Max_Tokens</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llmware/bling-stable-lm-3b-4e1t-v0</td>\n",
       "      <td>Every day, even when it is cloudy or cold, ev...</td>\n",
       "      <td>100</td>\n",
       "      <td>927.570463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llmware/bling-stable-lm-3b-4e1t-v0</td>\n",
       "      <td>Every day, even when it is cloudy, even when ...</td>\n",
       "      <td>200</td>\n",
       "      <td>1403.333939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  \\\n",
       "0  llmware/bling-stable-lm-3b-4e1t-v0   \n",
       "1  llmware/bling-stable-lm-3b-4e1t-v0   \n",
       "\n",
       "                                              Output  Max_Tokens         time  \n",
       "0   Every day, even when it is cloudy or cold, ev...         100   927.570463  \n",
       "1   Every day, even when it is cloudy, even when ...         200  1403.333939  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
